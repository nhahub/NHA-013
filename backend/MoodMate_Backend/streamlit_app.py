import streamlit as st
import pandas as pd
import numpy as np
import datetime
import os
import joblib
import warnings
import random
import json
import time 

# -------------------------------------------------------------
# Section 1: ML Logic and Preprocessing (In-Memory)
# -------------------------------------------------------------

# Suppress warnings
warnings.filterwarnings('ignore', category=UserWarning)
warnings.filterwarnings('ignore', category=FutureWarning)

# Final 30 columns for model (fixed order)
FINAL_OUTPUT_COLUMNS_ORDER = [
    'Gender', 'self_employed', 'family_history', 'Days_Indoors', 'Growing_Stress', 
    'Changes_Habits', 'Mental_Health_History', 'Mood_Swings', 'Coping_Struggles', 
    'Work_Interest', 'Social_Weakness', 'mental_health_interview', 'care_options', 
    'Year', 'Month', 'Day', 'Hour', 'Occupation_Business', 'Occupation_Corporate', 
    'Occupation_Housewife', 'Occupation_Others', 'Occupation_Student', 
    'Stress_Score', 'Social_Function_Score', 'SelfEmployment_Risk', 
    'Family_Support_Impact', 'Is_Winter', 'Is_MidYear', 'Is_Night', 
    'Country_TreatmentRate'
]

# Fixed scaling parameters (mean & std dev)
SCALING_PARAMS = {
    'Stress_Score': {'mean': 0.40, 'std': 0.30}, 'Social_Function_Score': {'mean': 0.05, 'std': 0.90},
    'Family_Support_Impact': {'mean': 0.30, 'std': 0.45}, 'Country_TreatmentRate': {'mean': 0.55, 'std': 0.15},
    'Year': {'mean': 2020.0, 'std': 3.0}, 'Month': {'mean': 6.0, 'std': 3.0},
    'Day': {'mean': 15.0, 'std': 8.0}, 'Hour': {'mean': 12.0, 'std': 5.0}
}
SCALING_COLS = list(SCALING_PARAMS.keys())

# Preprocessing functions (must match training pipeline)

def get_standard_key(answer, field_name):
    """Convert Arabic/colloquial answers to standardized English keys"""
    lower_answer = str(answer).lower().strip()
    
    if any(w in lower_answer for w in ['Ù†Ø¹Ù…', 'Ø§Ù‡', 'yes', 'Ù…ÙˆØ§ÙÙ‚', 'Ø£ÙƒÙŠØ¯', 'Ù„Ø³Ù‡', 'Ø¨Ù‚Ø¯Ø±', 'Ø¹Ø§Ø±Ù']): return 'Yes'
    if any(w in lower_answer for w in ['Ù„Ø§', 'no', 'Ø®Ø§Ù„Øµ', 'Ù…ÙÙŠØ´', 'ØµØ¹Ø¨', 'ÙÙ‚Ø¯Øª', 'Ù…Ø¨Ø®Ø±Ø¬Ø´']): return 'No'
    if any(w in lower_answer for w in ['ÙŠÙ…ÙƒÙ†', 'maybe', 'Ù…Ø´ Ù…ØªØ£ÙƒØ¯', 'Ù†Øµ Ù†Øµ', 'Ø£Ø­ÙŠØ§Ù†Ù‹Ø§', 'Ù…Ø´ Ø£ÙˆÙŠ']): return 'Maybe'
    if field_name == 'Gender':
        if any(w in lower_answer for w in ['Ø°ÙƒØ±', 'male', 'Ø±Ø¬Ù„']): return 'Male'
        if any(w in lower_answer for w in ['Ø£Ù†Ø«Ù‰', 'female', 'Ø¨Ù†Øª']): return 'Female'
    if field_name == 'Occupation':
        if any(w in lower_answer for w in ['Ø·Ø§Ù„Ø¨', 'student', 'Ø¨Ø¯Ø±Ø³', 'Ø¬Ø§Ù…Ø¹Ø©']): return 'Student'
        if any(w in lower_answer for w in ['Ù…ÙˆØ¸Ù', 'corporate', 'Ø¨Ø´ØªØºÙ„']): return 'Corporate'
        if any(w in lower_answer for w in ['Ø¹Ù…Ù„ Ø­Ø±', 'ÙØ±ÙŠÙ„Ø§Ù†Ø³Ø±', 'Ø¨Ø²Ù†Ø³']): return 'Business'
        if any(w in lower_answer for w in ['Ø±Ø¨Ø© Ù…Ù†Ø²Ù„', 'housewife']): return 'Housewife'
        if any(w in lower_answer for w in ['Ø¹Ø§Ø·Ù„', 'Ù„Ø§ Ø£Ø¹Ù…Ù„']): return 'Other'
    if field_name == 'Mood_Swings':
        if any(w in lower_answer for w in ['Ø¹Ø§Ù„ÙŠ', 'high', 'Ø³Ø±ÙŠØ¹', 'ÙƒØªÙŠØ±']): return 'High'
        if any(w in lower_answer for w in ['Ù…ØªÙˆØ³Ø·', 'medium', 'Ø¹Ø§Ø¯ÙŠ', 'Ø§Ø­ÙŠØ§Ù†Ø§']): return 'Medium'
        if any(w in lower_answer for w in ['Ù…Ù†Ø®ÙØ¶', 'low', 'Ù‚Ù„ÙŠÙ„', 'Ù†Ø§Ø¯Ø±']): return 'Low'
    if field_name == 'Days_Indoors':
        if any(w in lower_answer for w in ['ÙŠÙˆÙ…ÙŠØ§Ù‹', 'every day', 'ÙƒÙ„ ÙŠÙˆÙ…', 'Ø¨Ø®Ø±Ø¬']): return 'EveryDay'
        if any(w in lower_answer for w in ['Ø£ØºÙ„Ø¨ Ø§Ù„ÙˆÙ‚Øª', 'moderate', 'ÙƒØ§Ù… ÙŠÙˆÙ…']): return 'Moderate'
        if any(w in lower_answer for w in ['Ù†Ø§Ø¯Ø±Ù‹Ø§', 'isolated', 'Ù…Ø¨Ø®Ø±Ø¬Ø´', 'Ù‚Ø§Ø¹Ø¯']): return 'Isolated'
    return answer

def get_country_rate(country_name):
    """Map country to treatment rate"""
    lower_name = str(country_name).lower()
    if 'egypt' in lower_name or 'Ù…ØµØ±' in lower_name or 'saudi' in lower_name or 'Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©' in lower_name:
        return 0.75 
    return 0.50 

def apply_scaling(df):
    """Apply standardization to numerical features"""
    df_scaled = df.copy()
    for col in SCALING_COLS:
        if col in df_scaled.columns and SCALING_PARAMS[col]['std'] != 0:
            mean = SCALING_PARAMS[col]['mean']
            std = SCALING_PARAMS[col]['std']
            df_scaled[col] = (df_scaled[col] - mean) / std
    return df_scaled

# ---------------------------------------------
# Load core resources (model and JSON files)
# ---------------------------------------------

@st.cache_resource
def load_resources():
    """Load model and JSON data files (responses & solutions)"""
    
    base_dir = os.path.dirname(os.path.abspath(__file__)) 
    
    # Load model
    try:
        model = joblib.load(os.path.join(base_dir, 'health_chatbot_model.joblib'))
    except FileNotFoundError:
        st.error(f"âŒ Ø®Ø·Ø£: Ù…Ù„Ù Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ ('health_chatbot_model.joblib') ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ù…Ø³Ø§Ø± Ø§Ù„ØªØ·Ø¨ÙŠÙ‚.")
        model = None
        
    # Load JSON data files
    def load_json_data(file_name):
        full_path = os.path.join(base_dir, file_name)
        try:
            with open(full_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            st.error(f"âŒ Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù '{file_name}': ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù†Ù‡ Ø¨ØµÙŠØºØ© JSON Ø³Ù„ÙŠÙ…Ø© ÙˆÙ…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ù…Ø³Ø§Ø± Ø§Ù„ØªØ·Ø¨ÙŠÙ‚.")
            return None

    responses = load_json_data("responses.json")
    solutions = load_json_data("solutions.json")
    
    return model, responses, solutions

MODEL, RESPONSES, SOLUTIONS = load_resources()

# Stop app if resources failed to load
if MODEL is None or RESPONSES is None or SOLUTIONS is None:
    st.error("âš ï¸ ÙØ´Ù„ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ§Ø±Ø¯ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© (Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø£Ùˆ Ù…Ù„ÙØ§Øª JSON). ÙŠØ±Ø¬Ù‰ Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ ÙˆØ§Ù„Ù…Ø³Ø§Ø±Ø§Øª.")
    st.stop() 


def get_prediction_from_user_input(user_answers: dict) -> float:
    """Apply full preprocessing pipeline and generate prediction"""
    
    if MODEL is None: return 0.0

    df = pd.DataFrame([user_answers])
    
    # Ensure initial columns exist
    required_initial_cols = ['Gender', 'self_employed', 'family_history', 'Days_Indoors', 'Growing_Stress', 
                             'Changes_Habits', 'Mental_Health_History', 'Mood_Swings', 'Coping_Struggles', 
                             'Work_Interest', 'Social_Weakness', 'mental_health_interview', 'care_options', 
                             'Occupation', 'Country']
    for col in required_initial_cols:
        if col not in df.columns:
            default_value = 'No' if col in ['self_employed', 'family_history'] else 'Other' 
            df[col] = default_value

    df_ohe_source = df[['Occupation', 'Country']].copy() 

    # Apply linguistic standardization
    text_cols_to_interpret = df.select_dtypes(include=['object']).columns.tolist()
    for col in text_cols_to_interpret:
        if col in df.columns:
            df[col] = df.apply(lambda row: get_standard_key(row[col], col), axis=1)

    # Extract time features
    now = datetime.datetime.now()
    df['Year'], df['Month'], df['Day'], df['Hour'] = now.year, now.month, now.day, now.hour

    # Apply binary and ordinal encoding
    df['Gender'] = df['Gender'].map({'Male': 0, 'Female': 1}).fillna(0)
    df['self_employed'] = df['self_employed'].map({'No': 0, 'Yes': 1}).fillna(0)
    df['family_history'] = df['family_history'].map({'No': 0, 'Yes': 1}).fillna(0)
    df['Coping_Struggles'] = df['Coping_Struggles'].map({'No': 0, 'Yes': 1}).fillna(0)
    df['Days_Indoors'] = df['Days_Indoors'].map({'EveryDay': 0, 'Moderate': 1, 'Isolated': 4}).fillna(1)
    df['Mood_Swings'] = df['Mood_Swings'].map({'Low': 0, 'Medium': 1, 'High': 2}).fillna(0)
    
    # Apply label encoding for Yes/No/Maybe columns
    label_map = {'No': 0.0, 'Yes': 1.0, 'Maybe': 0.5}
    label_cols = [
        'Growing_Stress', 'Changes_Habits', 'Mental_Health_History',
        'Work_Interest', 'Social_Weakness', 'mental_health_interview', 'care_options'
    ]
    for col in label_cols:
        df[col] = df[col].map(label_map).fillna(0.0)
        
    # Create engineered features
    stress_cols = ['Days_Indoors', 'Growing_Stress', 'Changes_Habits', 'Coping_Struggles', 'Mood_Swings']
    df['Stress_Score'] = df[stress_cols].mean(axis=1)
    df['Social_Function_Score'] = (df['Work_Interest'] - df['Social_Weakness'])
    df['SelfEmployment_Risk'] = (df['self_employed'] * (1 - df['care_options']))
    df['Family_Support_Impact'] = (df['family_history'] * df['Coping_Struggles'])
    df['Is_MidYear'] = df['Month'].between(5, 8).astype(int)
    df['Is_Winter'] = df['Month'].apply(lambda x: 1 if x in [12, 1, 2] else 0)
    df['Is_Night'] = df['Hour'].apply(lambda x: 1 if x >= 21 or x <= 6 else 0)

    # Apply target encoding and drop Country column
    df['Country_TreatmentRate'] = df['Country'].apply(get_country_rate)
    df.drop('Country', axis=1, inplace=True) 
    
    # Apply scaling before OHE
    df = apply_scaling(df)

    # Restore Occupation for OHE
    df['Occupation'] = df_ohe_source['Occupation']
    
    # Apply one-hot encoding
    df_final = pd.get_dummies(df, columns=['Occupation'], dtype=int)
    
    # Ensure all OHE columns exist
    ohe_cols = ['Occupation_Business', 'Occupation_Corporate', 'Occupation_Housewife', 'Occupation_Others', 'Occupation_Student']
    for col in ohe_cols:
        if col not in df_final.columns:
            df_final[col] = 0

    # Enforce final column order
    df_ready = df_final.reindex(columns=FINAL_OUTPUT_COLUMNS_ORDER, fill_value=0)
    
    X_final = df_ready.values
    
    # Get prediction probability
    prediction_proba = MODEL.predict_proba(X_final)[0][1] 
    
    return float(prediction_proba)

# -------------------------------------------------------------
# Section 2: Conversation Analysis Functions
# -------------------------------------------------------------

def get_sentiment_score(text):
    """Simple sentiment analysis without TextBlob dependency"""
    if any(word in text for word in ["Ø²Ø¹Ù„Ø§Ù†", "ÙˆØ­Ø´", "ØªØ¹Ø¨Ø§Ù†", "Ø¶ÙŠÙ‚", "Ø­Ø²ÙŠÙ†", "Ù…ÙƒØªØ¦Ø¨"]): return -0.5
    if any(word in text for word in ["Ø³Ø¹ÙŠØ¯", "Ù…Ù…ØªØ§Ø²", "ÙƒÙˆÙŠØ³", "ÙØ±Ø­Ø§Ù†", "Ø¬Ù…ÙŠÙ„"]): return 0.5
    return 0.0

def get_empathetic_reply_and_key(user_text, question_config):
    """Match user input to predefined answer keys and return empathetic reply"""
    user_text_lower = user_text.lower()
    replies_config = question_config.get("answer_replies", {})
    
    # Try keyword matching
    for std_key, data in replies_config.items():
        if std_key != "Other":
            for keyword in data.get("keywords", []):
                if keyword in user_text_lower:
                    reply = random.choice(data.get("bot_reply", ["ØªÙ…Ø§Ù…."]))
                    return reply, std_key 
    
    # Try "Other" fallback
    if "Other" in replies_config:
        reply = random.choice(replies_config["Other"].get("bot_reply", ["ØªÙ…Ø§Ù…ØŒ Ø³Ø¬Ù„Øª Ø¯Ù‡."]))
        if question_config.get("field") == "Country":
            return reply, user_text 
        return reply, "Other"
        
    # No match found
    return None, user_text 

def check_mood_keywords(user_text):
    """Check if user message contains mood keywords"""
    if not RESPONSES or "mood_keywords" not in RESPONSES: return None 
    user_text_lower = user_text.lower()
    for mood in ["Ù…Ø¨Ø¶ÙˆÙ†", "ÙˆØ­Ø´", "ØªØ¹Ø¨Ø§Ù†", "Ø²Ø¹Ù„Ø§Ù†", "Ø³ÙŠØ¡"]:
        if mood in RESPONSES["mood_keywords"]:
            for keyword in RESPONSES["mood_keywords"][mood]:
                if keyword in user_text_lower:
                    return mood 
    for mood in ["Ù…Ù…ØªØ§Ø²", "ÙƒÙˆÙŠØ³"]:
        if mood in RESPONSES["mood_keywords"]:
            for keyword in RESPONSES["mood_keywords"][mood]:
                if keyword in user_text_lower:
                    return mood 
    return None 

def build_solutions_menu(collected_data):
    """Build list of problems based on collected answers"""
    problem_list = []
    if not SOLUTIONS: return []
    for problem_key, problem_data in SOLUTIONS.items():
        if problem_key == "final_summary": continue
        
        user_answer = collected_data.get(problem_key, "") 
        standard_key = get_standard_key(user_answer, problem_key)
        
        if standard_key in problem_data.get("trigger_answer", []):
            problem_list.append(problem_key) 
    return problem_list

def format_solution(problem_key):
    """Build complete solution message list for a given problem"""
    if not SOLUTIONS or problem_key not in SOLUTIONS: return ["Ø¢Ø³ÙØŒ Ù…Ø´ Ù„Ø§Ù‚ÙŠ Ø­Ù„ÙˆÙ„ Ù„Ù„Ù…Ø´ÙƒÙ„Ø© Ø¯ÙŠ."] 
    data = SOLUTIONS[problem_key]
    response_list = [] 
    
    # Add problem intro and description
    if "problem_intro" in data and data["problem_intro"]: response_list.append(data['problem_intro'])
    else: response_list.append(f"ØªÙ…Ø§Ù…ØŒ Ø®Ù„ÙŠÙ†Ø§ Ù†ØªÙƒÙ„Ù… Ø¹Ù† **{data['problem_name']}**.")
      
    if data.get("descriptions") and data["descriptions"]:
        response_list.append(f"**Ù…Ù„Ø®Øµ Ø§Ù„Ù…Ø´ÙƒÙ„Ø©:**\n{random.choice(data['descriptions'])}")
    
    # Add practical solutions (pick 2 random)
    if data.get("solutions") and data["solutions"]:
        sol_text = "**Ø·ÙŠØ¨ØŒ Ø¥ÙŠÙ‡ Ø­Ù„ÙŠÙ† Ø¹Ù…Ù„ÙŠÙŠÙ† Ù…Ù‚ØªØ±Ø­ÙŠÙ†ØŸ**\n"
        k = min(len(data["solutions"]), 2) 
        chosen_solutions = random.sample(data["solutions"], k)
        for i, sol in enumerate(chosen_solutions):
            sol_text += f"\n**{i+1}.** {sol}"
        response_list.append(sol_text) 
    
    # Add video and podcast resources
    if data.get("videos") and data["videos"]: 
        response_list.append(f"\n{data.get('video_intro', 'ÙÙŠØ¯ÙŠÙˆÙ‡Ø§Øª Ù…Ù‚ØªØ±Ø­Ø©:')}\n- [Ø´Ø§Ù‡Ø¯ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ]({random.choice(data['videos'])})")
            
    if data.get("podcasts") and data["podcasts"]: 
        response_list.append(f"\n{data.get('podcast_intro', 'Ø¨ÙˆØ¯ÙƒØ§Ø³Øª Ù…Ù‚ØªØ±Ø­:')}\n- [Ø§Ø³ØªÙ…Ø¹ Ù„Ù„Ø¨ÙˆØ¯ÙƒØ§Ø³Øª]({random.choice(data['podcasts'])})")
            
    return response_list 


def reset_session():
    """Reset session state to initial values"""
    st.session_state.convo_state = {
        "mode": "greeting", 
        "current_question_index": 0,
        "collected_data": {},
        "problem_list": [] 
    }

# -------------------------------------------------------------
# Section 3: Main Streamlit Interface and Flow Logic
# -------------------------------------------------------------

st.set_page_config(page_title="MoodMate", page_icon="ðŸ¤–")
st.title("ðŸ¤– MoodMate")
st.caption("Ø£Ù†Ø§ ØµØ¯ÙŠÙ‚Ùƒ Ø§Ù„Ù†ÙØ³ÙŠØŒ ÙˆÙ…ÙˆØ¬ÙˆØ¯ Ù‡Ù†Ø§ Ø¹Ø´Ø§Ù† Ø£Ø³Ù…Ø¹Ùƒ.")

# Apply RTL for Arabic
st.markdown("""
<style>
div[data-testid="chat-message-container"] {direction: rtl; text-align: right;}
div[data-testid="stTextInput"] > div > div > input {direction: rtl; text-align: right;}
</style>
""", unsafe_allow_html=True)

# Initialize message history
if "messages" not in st.session_state:
    st.session_state.messages = []
    initial_greeting = random.choice(RESPONSES["greetings"]["Ø¹Ø§Ù…"]) + " Ø¹Ø§Ù…Ù„ Ø¥ÙŠÙ‡ Ø§Ù„Ù†Ù‡Ø§Ø±Ø¯Ù‡ØŸ"
    st.session_state.messages.append({"role": "assistant", "content": initial_greeting})

# Initialize conversation state
if "convo_state" not in st.session_state:
    reset_session() 

# Display all previous messages
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# Main chat logic

if user_prompt := st.chat_input("Ø§ÙƒØªØ¨ Ø±Ø³Ø§Ù„ØªÙƒ Ù‡Ù†Ø§..."):
    # Display user message
    st.chat_message("user").markdown(user_prompt)
    st.session_state.messages.append({"role": "user", "content": user_prompt})

    # Begin bot logic
    user_text = user_prompt.strip()
    state = st.session_state.convo_state 
    
    # Check for keywords
    is_farewell = any(keyword in user_text.lower() for keyword in RESPONSES.get("farewell_keywords", []))
    mood_key_check = check_mood_keywords(user_text)
    is_negative_trigger = mood_key_check in ["ÙˆØ­Ø´", "ØªØ¹Ø¨Ø§Ù†", "Ù…Ø¨Ø¶ÙˆÙ†", "Ø²Ø¹Ù„Ø§Ù†", "Ø³ÙŠØ¡"]
    is_greeting = any(keyword in user_text.lower() for keyword in RESPONSES["greetings_keywords"]["Ø¹Ø§Ù…"]) and len(user_text.split()) < 4
    
    # Fix stuck memory if user triggers reset keywords
    if (state["mode"] != "greeting") and (is_farewell or is_negative_trigger or is_greeting):
          reset_session()
          state = st.session_state.convo_state
        
    # State machine logic (ordered by priority)

    # State: farewell
    if is_farewell:
        bot_response = random.choice(RESPONSES.get('farewells'))
        with st.chat_message("assistant"): st.markdown(bot_response)
        st.session_state.messages.append({"role": "assistant", "content": bot_response})
        reset_session()
        
    # State: awaiting confirmation
    elif state["mode"] == "awaiting_confirmation":
        conf_keywords = RESPONSES["interview_intro"]["confirmation_keywords"]
        if any(keyword in user_text.lower() for keyword in conf_keywords):
            state["mode"] = "in_interview"
            first_question = RESPONSES["interview_questions"][0]
            state["current_question_index"] = 0
            bot_response = first_question["question"]
        else:
            state["mode"] = "greeting" 
            bot_response = "ØªÙ…Ø§Ù…ØŒ Ø¨Ø±Ø§Ø­ØªÙƒ Ø¬Ø¯Ù‹Ø§. Ù„Ùˆ Ø­Ø¨ÙŠØª Ù†Ø¨Ø¯Ø£ ÙÙŠ Ø£ÙŠ ÙˆÙ‚ØªØŒ Ù‚ÙˆÙ„ÙŠ Ø¨Ø³ Ø¥Ù†Ùƒ Ù…ØªØ¶Ø§ÙŠÙ‚ Ø£Ùˆ Ø²Ù‡Ù‚Ø§Ù†."
        with st.chat_message("assistant"): st.markdown(bot_response)
        st.session_state.messages.append({"role": "assistant", "content": bot_response})
        
    # State: inside interview
    elif state["mode"] == "in_interview":
        last_q_index = state["current_question_index"]
        last_q_config = RESPONSES["interview_questions"][last_q_index]

        empathetic_reply, stored_key = get_empathetic_reply_and_key(user_text, last_q_config)
        
        # Handle failed match (unclear response)
        if empathetic_reply is None:
            bot_response = random.choice(RESPONSES.get("unclear_responses"))
            with st.chat_message("assistant"): st.markdown(bot_response)
            st.session_state.messages.append({"role": "assistant", "content": bot_response})
            st.rerun() 
            
        # Successful match - store answer
        state["collected_data"][last_q_config["field"]] = stored_key
        
        with st.chat_message("assistant"):
            with st.spinner("..."): time.sleep(0.5)
            st.markdown(empathetic_reply)
        st.session_state.messages.append({"role": "assistant", "content": empathetic_reply})

        # Check if more questions remain
        next_q_index = last_q_index + 1
        if next_q_index < len(RESPONSES["interview_questions"]):
            next_question = RESPONSES["interview_questions"][next_q_index]
            state["current_question_index"] = next_q_index
            bot_response = next_question["question"] 
            with st.chat_message("assistant"):
                with st.spinner("..."): time.sleep(0.5)
                st.markdown(bot_response)
            st.session_state.messages.append({"role": "assistant", "content": bot_response})
        else:
            # Interview complete
            # Send completion message
            with st.chat_message("assistant"):
                with st.spinner("..."): time.sleep(1.0)
                st.markdown(RESPONSES["interview_end"])
            st.session_state.messages.append({"role": "assistant", "content": RESPONSES["interview_end"]})
            
            # Generate prediction
            prediction_result = get_prediction_from_user_input(state["collected_data"]) 
            
            # Calculate and display stability score
            risk_percentage = prediction_result * 100
            stability_score = 100 - risk_percentage
            
            # Determine appropriate advice message
            if stability_score >= 95:
                advice = "âœ… Ù‡Ø°Ø§ ÙŠØ¹Ù†ÙŠ Ø£Ù† Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ù„Ø§ ÙŠØ±Ù‰ Ø­Ø§Ù„ÙŠÙ‹Ø§ Ø¶Ø±ÙˆØ±Ø© Ù…Ù„Ø­Ø© Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø±Ø¹Ø§ÙŠØ© Ù…ØªØ®ØµØµØ©."
            elif stability_score < 50:
                advice = "ðŸš¨ Ø§Ù„Ù†Ø³Ø¨Ø© Ù…Ù†Ø®ÙØ¶Ø©ØŒ ÙŠØ±Ø¬Ù‰ Ø§Ù„ØªÙÙƒÙŠØ± Ø¬Ø¯ÙŠØ§Ù‹ ÙÙŠ Ø§Ù„Ø®ÙŠØ§Ø±Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø© Ù„Ù„Ù…Ø³Ø§Ø¹Ø¯Ø©."
            else:
                advice = "âš ï¸ Ø§Ù„Ù†Ø³Ø¨Ø© Ø¬ÙŠØ¯Ø©ØŒ Ù„ÙƒÙ† ÙŠÙØ¶Ù„ Ù…ØªØ§Ø¨Ø¹Ø© Ø§Ù„Ø­Ù„ÙˆÙ„ Ø§Ù„ØªÙŠ Ø³Ù†Ø¹Ø±Ø¶Ù‡Ø§."
                
            # Display prediction message
            with st.chat_message("assistant"):
                with st.spinner("..."): time.sleep(1.0)
                
                bot_response_prediction_main = (
                    f"Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ ØªØ­Ù„ÙŠÙ„ Ø¥Ø¬Ø§Ø¨Ø§ØªÙƒØŒ ÙŠÙØ¸Ù‡Ø± Ù†Ù…ÙˆØ°Ø¬Ù†Ø§ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠ Ø£Ù† Ù†Ø³Ø¨Ø© **Ø§Ù„ØµØ­Ø© Ø§Ù„Ù†ÙØ³ÙŠØ© Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø©** Ù„Ø¯ÙŠÙƒ "
                    f"Ù‡ÙŠ: **{stability_score:.2f}%** ØªÙ‚Ø±ÙŠØ¨Ù‹Ø§."
                )
                
                st.markdown(bot_response_prediction_main)
            st.session_state.messages.append({"role": "assistant", "content": bot_response_prediction_main})
            
            # Display advice message
            with st.chat_message("assistant"):
                 with st.spinner("..."): time.sleep(0.5)
                 st.markdown(advice)
            st.session_state.messages.append({"role": "assistant", "content": advice})
            
            # Build and display solutions menu
            problem_list = build_solutions_menu(state["collected_data"])
            
            if not problem_list:
                bot_response = "Ø¨ØµØ±Ø§Ø­Ø©ØŒ Ù…Ù† Ø¥Ø¬Ø§Ø¨Ø§ØªÙƒ Ø§Ù„Ù†ÙØ³ÙŠØ©ØŒ Ø£Ù†Ø§ Ø´Ø§ÙŠÙ Ø¥Ù†Ùƒ ÙÙŠ Ø­Ø§Ù„Ø© ÙƒÙˆÙŠØ³Ø© ÙˆÙ…Ø´ Ù…Ø­ØªØ§Ø¬ Ø£ÙŠ Ø­Ù„ÙˆÙ„. Ù„Ùˆ Ø­Ø§Ø¨Ø¨ ØªØªÙƒÙ„Ù… ÙÙŠ Ø£ÙŠ Ø­Ø§Ø¬Ø© ØªØ§Ù†ÙŠØ© Ø£Ù†Ø§ Ù…ÙˆØ¬ÙˆØ¯!"
                state["mode"] = "final_summary"
            else:
                state["problem_list"] = problem_list
                state["mode"] = "solutions_menu"
                menu_text = "ÙˆØ¯Ù„ÙˆÙ‚ØªÙŠØŒ Ø®Ù„ÙŠÙ†Ø§ Ù†ØªÙƒÙ„Ù… ÙÙŠ (Ø§Ù„Ø­Ù„ÙˆÙ„ Ø§Ù„Ù†ÙØ³ÙŠØ©) Ù„Ù„Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„Ù„ÙŠ Ø¥Ù†Øª Ø°ÙƒØ±ØªÙ‡Ø§. Ø£Ù†Ø§ Ù„Ø§Ø­Ø¸Øª Ø¥Ù†Ù†Ø§ Ù…Ù…ÙƒÙ† Ù†ØªÙƒÙ„Ù… ÙÙŠ Ø§Ù„Ù†Ù‚Ø· Ø¯ÙŠ:\n\n"
                for i, problem_key in enumerate(problem_list):
                    problem_name = SOLUTIONS[problem_key].get("problem_name", problem_key)
                    menu_text += f"**{i+1}. {problem_name}**\n"
                menu_text += "\nØªØ­Ø¨ Ù†Ø¨Ø¯Ø£ Ø¨Ø£Ù†Ù‡ÙŠ ÙˆØ§Ø­Ø¯Ø© ÙÙŠÙ‡Ù…ØŸ (Ø§ÙƒØªØ¨ Ø§Ù„Ø±Ù‚Ù… Ø£Ùˆ Ø§Ù„Ø§Ø³Ù…)"
                bot_response = menu_text
            
            with st.chat_message("assistant"):
                with st.spinner("..."): time.sleep(1.0)
                st.markdown(bot_response)
            st.session_state.messages.append({"role": "assistant", "content": bot_response})
            
    # State: solutions menu
    elif state["mode"] == "solutions_menu":
        chosen_problem = None
        if SOLUTIONS and "problem_list" in state: 
            for i, problem_key in enumerate(state["problem_list"]):
                problem_name = SOLUTIONS.get(problem_key, {}).get("problem_name", "")
                if (str(i+1) == user_text) or (problem_name and problem_name.lower() in user_text.lower()) or (problem_key.lower() in user_text.lower()):
                    chosen_problem = problem_key
                    break
            
        if chosen_problem:
            solution_responses = format_solution(chosen_problem)
            state["problem_list"].remove(chosen_problem)
            
            # Display all solution messages
            for response in solution_responses:
                with st.chat_message("assistant"):
                    with st.spinner("..."): time.sleep(0.5) 
                    st.markdown(response)
                st.session_state.messages.append({"role": "assistant", "content": response})

            # Check if more problems remain
            with st.chat_message("assistant"):
                with st.spinner("..."): time.sleep(0.5)
                if state["problem_list"]:
                    bot_response = "\n\n--- (ÙØ§ØµÙ„) ---\nØªØ­Ø¨ Ù†ÙƒÙ…Ù„ ÙÙŠ Ø§Ù„Ù†Ù‚Ø· Ø§Ù„Ø¨Ø§Ù‚ÙŠØ©ØŸ (Ù‚ÙˆÙ„ 'ÙƒÙ…Ù„' Ø£Ùˆ 'Ù„Ø§')"
                    state["mode"] = "solutions_flow"
                else:
                    state["mode"] = "final_summary"
                    bot_response = "âœ… Ø®Ù„ØµÙ†Ø§ ÙƒÙ„ Ø§Ù„Ø­Ù„ÙˆÙ„! Ø¬Ø§Ø±ÙŠ Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø®Ø§ØªÙ…Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©."
                
                st.markdown(bot_response)
                st.session_state.messages.append({"role": "assistant", "content": bot_response})
        else:
            bot_response = "Ø¢Ø³Ù Ù…Ø´ ÙØ§Ù‡Ù…. Ù…Ù…ÙƒÙ† ØªØ®ØªØ§Ø± Ø±Ù‚Ù… Ø£Ùˆ Ø§Ø³Ù… Ø§Ù„Ù…Ø´ÙƒÙ„Ø© Ù…Ù† Ø§Ù„Ù‚Ø§ÙŠÙ…Ø©ØŸ"
            with st.chat_message("assistant"): st.markdown(bot_response)
            st.session_state.messages.append({"role": "assistant", "content": bot_response})
            
    # State: solutions flow continuation
    elif state["mode"] == "solutions_flow":
        if any(keyword in user_text.lower() for keyword in ["Ù†Ø¹Ù…", "Ø§Ù‡", "Ù…Ø§Ø´ÙŠ", "ØªÙ…Ø§Ù…", "ÙƒÙ…Ù„"]):
            state["mode"] = "solutions_menu"
            menu_text = "ØªÙ…Ø§Ù…. Ø¯ÙŠ Ø§Ù„Ù†Ù‚Ø· Ø§Ù„Ø¨Ø§Ù‚ÙŠØ© Ø§Ù„Ù„ÙŠ Ù…Ù…ÙƒÙ† Ù†ØªÙƒÙ„Ù… ÙÙŠÙ‡Ø§:\n\n"
            for i, problem_key in enumerate(state["problem_list"]):
                problem_name = SOLUTIONS[problem_key]["problem_name"]
                menu_text += f"**{i+1}. {problem_name}**\n"
            menu_text += "\nØªØ­Ø¨ Ù†Ø®ØªØ§Ø± Ø£Ù†Ù‡ÙŠ ÙˆØ§Ø­Ø¯Ø©ØŸ"
            bot_response = menu_text
        else:
            state["mode"] = "final_summary" 
            summary_messages = SOLUTIONS.get("final_summary", {}).get("messages", ["Ø´ÙƒØ±Ù‹Ø§ Ù„ÙˆÙ‚ØªÙƒ. Ù„Ùˆ Ø§Ø­ØªØ¬Øª Ø£ÙŠ Ø­Ø§Ø¬Ø© ØªØ§Ù†ÙŠØ©ØŒ Ø£Ù†Ø§ Ù…ÙˆØ¬ÙˆØ¯!"])
            bot_response = "\n".join(summary_messages)
            
        with st.chat_message("assistant"): st.markdown(bot_response)
        st.session_state.messages.append({"role": "assistant", "content": bot_response})
        
# State: final summary
    elif state["mode"] == "final_summary":
        summary_messages = SOLUTIONS.get("final_summary", {}).get("messages", ["Ø´ÙƒØ±Ù‹Ø§ Ù„ÙˆÙ‚ØªÙƒ. Ù„Ùˆ Ø§Ø­ØªØ¬Øª Ø£ÙŠ Ø­Ø§Ø¬Ø© ØªØ§Ù†ÙŠØ©ØŒ Ø£Ù†Ø§ Ù…ÙˆØ¬ÙˆØ¯!"])
        
        # Display all summary messages
        for msg in summary_messages:
            with st.chat_message("assistant"):
                with st.spinner("..."): time.sleep(0.5) 
                st.markdown(msg)
            st.session_state.messages.append({"role": "assistant", "content": msg})
            
        reset_session() 

    # State: greeting/normal conversation
    elif state["mode"] == "greeting":
        
        mood_key_check = check_mood_keywords(user_text)
        
        # Handle greeting
        if is_greeting: 
            bot_response = f"{random.choice(RESPONSES['greetings']['Ø¹Ø§Ù…'])} Ø¹Ø§Ù…Ù„ Ø¥ÙŠÙ‡ Ø§Ù„Ù†Ù‡Ø§Ø±Ø¯Ù‡ØŸ"
        # Handle negative mood trigger
        elif mood_key_check in ["ÙˆØ­Ø´", "ØªØ¹Ø¨Ø§Ù†", "Ù…Ø¨Ø¶ÙˆÙ†", "Ø²Ø¹Ù„Ø§Ù†", "Ø³ÙŠØ¡"]:
            bot_response = RESPONSES["interview_intro"]["speech"]
            state["mode"] = "awaiting_confirmation"
        # Handle positive mood
        elif mood_key_check in ["Ù…Ù…ØªØ§Ø²", "ÙƒÙˆÙŠØ³"]:
            bot_response = random.choice(RESPONSES["mood_responses"][mood_key_check]["responses"])
        # Sentiment-based fallback
        else:
            sentiment_score = get_sentiment_score(user_text)
            if sentiment_score < -0.2: 
                bot_response = RESPONSES["interview_intro"]["speech"]
                state["mode"] = "awaiting_confirmation" 
            elif sentiment_score > 0.3: 
                bot_response = random.choice(RESPONSES["mood_responses"]["Ù…Ù…ØªØ§Ø²"]["responses"])
            else:
                bot_response = random.choice(RESPONSES.get("unclear_responses"))
            
        with st.chat_message("assistant"): st.markdown(bot_response)
        st.session_state.messages.append({"role": "assistant", "content": bot_response})
        
    # Save updated state to session
    st.session_state.convo_state = state
        
    st.rerun()